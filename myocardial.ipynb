{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Nabil Ibtehaz (https://github.com/nibtehaz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import  tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOMED_CODES = {\n",
    "    '164865005' : 'EKG: myocardial infarction',\n",
    "    '164889003' : 'ECG: atrial fibrillation',\n",
    "    '164890007': 'EKG: atrial flutter',\n",
    "    '164895002' : 'EKG: ventricular tachycardia',\n",
    "    '164896001' : 'EKG: ventricular fibrillation',\n",
    "    '426783006' : 'ECG: sinus rhythm',\n",
    "    '6374002' : 'Bundle branch block',\n",
    "    '53741008' : 'Coronary arteriosclerosis'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dx_dict.keys()).intersection(set(cls_lbl.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(dx,len(dx_dict[dx])) for dx in dx_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(list(dx_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/st_petersburg_incart/g1/I0013.hea')\n",
    "print(fp.read())\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [fl.split('.')[0] for fl in next(os.walk('/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1'))[2] if '.mat' in fl]\n",
    "\n",
    "ecg_data = ['/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/'+fl for fl in files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/S0173.hea','r')\n",
    "dt = fp.read().split('\\n')[:-1]\n",
    "fp.close()\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_dict = {}\n",
    "myo_label = {0:[],1:[]}\n",
    "\n",
    "for fl in files:\n",
    "    fp = open(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{fl}.hea','r')\n",
    "    dt = fp.read().split('\\n')[:-1]\n",
    "    fp.close()\n",
    "\n",
    "    dxs = dt[15][6:].split(',')\n",
    "    #print(dxs)\n",
    "    #print(dt[15])\n",
    "\n",
    "    for dx in dxs:\n",
    "        if dx not in dx_dict:\n",
    "            dx_dict[dx] = []\n",
    "\n",
    "        dx_dict[dx].append(fl)\n",
    "\n",
    "    if '164865005' in dt[15]:\n",
    "        myo_label[1].append(fl)\n",
    "    else:\n",
    "        myo_label[0].append(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(myo_label[0]),len(myo_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_files = []\n",
    "record_labels = []\n",
    "\n",
    "for c in myo_label:\n",
    "    for s in myo_label[c]:\n",
    "        record_files.append(s)\n",
    "        record_labels.append(c)\n",
    "\n",
    "record_files = np.array(record_files)\n",
    "record_labels = np.array(record_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "splits = {}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(record_files, record_labels)):\n",
    "    splits[i] = {\n",
    "        'train' : record_files[train_index],\n",
    "        'test' : record_files[test_index],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump((splits,record_files,record_labels), open('./myo_processed/data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(splits,record_files,record_labels) = pickle.load(open('./myo_processed/data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(cls_lbl[dx], len(dx_dict[dx])) for dx in dx_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "sig = loadmat(ecg_data[idx]+'.mat')['val'] * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( (sig[0,17500:22500] - np.mean(sig[0,2500:5000]))/(np.std(sig[0,2500:7500])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig[0,2500:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig2 = downsample2(sig[0,17500:22500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig[0,17500:22500])\n",
    "plt.figure(0)\n",
    "plt.plot(sig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample2(sig):\n",
    "    return (sig[np.arange(0,5000,2)] + sig[np.arange(1,5000,2)])/2\n",
    "\n",
    "def downsample2_12(sig):\n",
    "    return (sig[:,np.arange(0,5000,2)] + sig[:,np.arange(1,5000,2)])/2\n",
    "\n",
    "def mean_norm(sig):\n",
    "    return (sig-np.mean(sig))/(np.std(sig)+1e-6)\n",
    "\n",
    "def mean_norm12(sig):\n",
    "    return (sig-np.mean(sig,axis=1,keepdims=True))/(np.std(sig,axis=1,keepdims=True)+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabil/ecg_repr/ecg_repr/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/nabil/ecg_repr/ecg_repr/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from MAE1DCorrelated import MaskedAutoencoderViT1DCorrelated\n",
    "from MAE1D import MaskedAutoencoderViT1D\n",
    "from MAEBank import MAEBank\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae12 = MaskedAutoencoderViT1D(window_len=100, in_chans=12, embed_dim=768, depth=12, num_heads=8,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16)\n",
    "mae12.load_state_dict(torch.load('./experiments/expb_baseline_200/model_best.pth',map_location='cpu')[\"model\"])\n",
    "\n",
    "mae12.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config\n",
      "MaskedAutoencoderViT1D(sig_len=2500, window_len=100, in_chans=1,embed_dim=768, depth=12, num_heads=8,decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=512,mlp_ratio=4.0, norm_layer=<class 'torch.nn.modules.normalization.LayerNorm'>, norm_pix_loss=True)\n"
     ]
    }
   ],
   "source": [
    "mae1 = MaskedAutoencoderViT1D(window_len=100, in_chans=1, embed_dim=768, depth=12, num_heads=8,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16)\n",
    "mae1.load_state_dict(torch.load('./experiments/expb_baseline_4_200/model_best.pth',map_location='cpu')[\"model\"])\n",
    "mae1.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config\n",
      "MaskedAutoencoderViT1D(sig_len=2500, window_len=100, in_chans=1,embed_dim=768, depth=12, num_heads=8,decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=512,mlp_ratio=4.0, norm_layer=<class 'torch.nn.modules.normalization.LayerNorm'>, norm_pix_loss=True)\n",
      "Initializing MAE 1\n",
      "Initializing MAE 2\n",
      "Initializing MAE 3\n",
      "Initializing MAE 4\n",
      "Initializing MAE 5\n",
      "Initializing MAE 6\n",
      "Initializing MAE 7\n",
      "Initializing MAE 8\n",
      "Initializing MAE 9\n",
      "Initializing MAE 10\n",
      "Initializing MAE 11\n",
      "Initializing MAE 12\n"
     ]
    }
   ],
   "source": [
    "mae_bank = MAEBank(['cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae1c = mae_bank.maes[3]\n",
    "mae1c.load_state_dict(torch.load('./experiments/expb3/saved_models/mae_channel_4_best.pth',map_location='cpu'))\n",
    "\n",
    "mae1c.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_bank = MAEBank(['cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "devc = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae12.to(devc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1.to(devc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1c.to(devc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae2c.to(devc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [02:28<00:00,  2.78it/s]\n",
      "100%|██████████| 104/104 [00:09<00:00, 11.54it/s]\n",
      "100%|██████████| 413/413 [00:22<00:00, 18.39it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 18.41it/s]\n",
      "100%|██████████| 413/413 [00:24<00:00, 16.94it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 19.37it/s]\n",
      "100%|██████████| 413/413 [00:30<00:00, 13.55it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 17.31it/s]\n",
      "100%|██████████| 413/413 [00:30<00:00, 13.33it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 19.61it/s]\n"
     ]
    }
   ],
   "source": [
    "msk_ratio = 0.00\n",
    "n_tries = 1\n",
    "chnl = 4\n",
    "\n",
    "sig1_train = {}\n",
    "lbl1_train = {}\n",
    "\n",
    "sig1_valid = {}\n",
    "lbl1_valid = {}\n",
    "\n",
    "\n",
    "for split in range(5):\n",
    "\n",
    "    sig1_train[split] = []\n",
    "    lbl1_train[split] = []\n",
    "\n",
    "    sig1_valid[split] = {}\n",
    "    lbl1_valid[split] = {}\n",
    "\n",
    "\n",
    "    for prsn in tqdm(splits[split]['train']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl-1,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))\n",
    "            lbl1_train[split].append(lbl)\n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to(devc)\n",
    "            latent, mask, ids_restore = mae1.forward_encoder(x, msk_ratio)\n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        if (len(sig1_train[split]))==0:\n",
    "            sig1_train[split] = latent[:,0,:].detach().numpy()\n",
    "        else:\n",
    "            sig1_train[split] = np.vstack([sig1_train[split],latent[:,0,:].detach().numpy()])\n",
    "\n",
    "\n",
    "    for prsn in tqdm(splits[split]['test']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl-1,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))        \n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to(devc)\n",
    "\n",
    "            latent, mask, ids_restore = mae1.forward_encoder(x, msk_ratio)\n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        \n",
    "        sig1_valid[split][prsn] = latent[:,0,:].detach().numpy()\n",
    "        lbl1_valid[split][prsn] = lbl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((sig1_train,lbl1_train,sig1_valid,lbl1_valid), open('./myo_processed/mae4.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_ratio = 0.00\n",
    "n_tries = 1\n",
    "\n",
    "sig12_train = {}\n",
    "lbl12_train = {}\n",
    "\n",
    "sig12_valid = {}\n",
    "lbl12_valid = {}\n",
    "\n",
    "for split in range(5):\n",
    "\n",
    "    sig12_train[split] = []\n",
    "    lbl12_train[split] = []\n",
    "\n",
    "    sig12_valid[split] = {}\n",
    "    lbl12_valid[split] = {}\n",
    "\n",
    "    for prsn in tqdm(splits[split]['train']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0    \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig[0])-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm12(downsample2_12(sig[:,st_smpl:st_smpl+5000])))\n",
    "            lbl12_train[split].append(lbl)\n",
    "\n",
    "        x = torch.Tensor(sig_epsd)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = x.to(devc)\n",
    "\n",
    "            latent, mask, ids_restore = mae12.forward_encoder(x, msk_ratio)\n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        if (len(sig12_train[split]))==0:\n",
    "            sig12_train[split] = latent[:,0,:].detach().numpy()\n",
    "        else:\n",
    "            sig12_train[split] = np.vstack([sig12_train[split],latent[:,0,:].detach().numpy()])\n",
    "\n",
    "\n",
    "    for prsn in tqdm(splits[split]['test']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0    \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig[0])-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm12(downsample2_12(sig[:,st_smpl:st_smpl+5000])))        \n",
    "\n",
    "        x = torch.Tensor(sig_epsd)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to(devc)\n",
    "\n",
    "            latent, mask, ids_restore = mae12.forward_encoder(x, msk_ratio)\n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        \n",
    "        sig12_valid[split][prsn] = latent[:,0,:].detach().numpy()\n",
    "        lbl12_valid[split][prsn] = lbl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump((sig12_train,lbl12_train,sig12_valid,lbl12_valid), open('./myo_processed/mae12.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [01:01<00:00,  6.73it/s]\n",
      "100%|██████████| 104/104 [00:08<00:00, 11.68it/s]\n",
      "100%|██████████| 413/413 [00:21<00:00, 19.21it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 20.41it/s]\n",
      "100%|██████████| 413/413 [00:22<00:00, 18.37it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 20.17it/s]\n",
      "100%|██████████| 413/413 [00:24<00:00, 17.05it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 20.24it/s]\n",
      "100%|██████████| 413/413 [00:29<00:00, 13.82it/s]\n",
      "100%|██████████| 103/103 [00:05<00:00, 19.62it/s]\n"
     ]
    }
   ],
   "source": [
    "msk_ratio = 0.00\n",
    "n_tries = 1\n",
    "chnl = 4\n",
    "\n",
    "sig1c_train = {}\n",
    "lbl1c_train = {}\n",
    "\n",
    "sig1c_valid = {}\n",
    "lbl1c_valid = {}\n",
    "\n",
    "\n",
    "for split in range(5):\n",
    "\n",
    "    sig1c_train[split] = []\n",
    "    lbl1c_train[split] = []\n",
    "\n",
    "    sig1c_valid[split] = {}\n",
    "    lbl1c_valid[split] = {}\n",
    "\n",
    "    for prsn in tqdm(splits[split]['train']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl-1,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))\n",
    "            lbl1c_train[split].append(lbl)\n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            ids_shuffle, ids_restore, ids_keep = mae_bank.propose_masking(len(x), mae_bank.num_patches, msk_ratio)\n",
    "\n",
    "            x = x.to(devc)\n",
    "            ids_shuffle = ids_shuffle.to(devc)\n",
    "            ids_restore = ids_restore.to(devc)\n",
    "            ids_keep = ids_keep.to(devc)\n",
    "\n",
    "            latent, mask = mae1c.forward_encoder(x, msk_ratio, ids_shuffle, ids_restore, ids_keep)        \n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_shuffle = ids_shuffle.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            ids_keep = ids_keep.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        if (len(sig1c_train[split]))==0:\n",
    "            sig1c_train[split] = latent[:,0,:].detach().numpy()\n",
    "        else:\n",
    "            sig1c_train[split] = np.vstack([sig1c_train[split],latent[:,0,:].detach().numpy()])\n",
    "\n",
    "\n",
    "    for prsn in tqdm(splits[split]['test']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl-1,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))        \n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ids_shuffle, ids_restore, ids_keep = mae_bank.propose_masking(len(x), mae_bank.num_patches, msk_ratio)\n",
    "\n",
    "            x = x.to(devc)\n",
    "            ids_shuffle = ids_shuffle.to(devc)\n",
    "            ids_restore = ids_restore.to(devc)\n",
    "            ids_keep = ids_keep.to(devc)\n",
    "\n",
    "            latent, mask = mae1c.forward_encoder(x, msk_ratio, ids_shuffle, ids_restore, ids_keep)        \n",
    "            \n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_shuffle = ids_shuffle.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            ids_keep = ids_keep.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        \n",
    "        sig1c_valid[split][prsn] = latent[:,0,:].detach().numpy()\n",
    "        lbl1c_valid[split][prsn] = lbl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((sig1c_train,lbl1c_train,sig1c_valid,lbl1c_valid), open('./myo_processed/mae4c.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2677960\n",
      "drwxrwxr-x  2 nabil nabil      4096 Aug 14 15:22 .\n",
      "drwxrwxr-x 12 nabil nabil      4096 Aug 11 22:31 ..\n",
      "-rw-rw-r--  1 nabil nabil     66663 Aug 14 12:25 data.p\n",
      "-rw-rw-r--  1 nabil nabil 342764024 Aug 11 17:50 mae12_old.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 12:48 mae12.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 15:33 mae1c.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 11 17:58 mae1_old.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 13:02 mae1.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 15:41 mae2c.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 13:17 mae2.p\n",
      "-rw-rw-r--  1 nabil nabil 342764008 Aug 14 15:22 mae3.p\n"
     ]
    }
   ],
   "source": [
    "!ls -all myo_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_ratio = 0.00\n",
    "n_tries = 1\n",
    "\n",
    "sig1c_train = {}\n",
    "lbl1c_train = {}\n",
    "\n",
    "sig1c_valid = {}\n",
    "lbl1c_valid = {}\n",
    "\n",
    "chnl_id = 1\n",
    "\n",
    "for split in range(5):\n",
    "\n",
    "    sig1c_train[split] = []\n",
    "    lbl1c_train[split] = []\n",
    "\n",
    "    sig1c_valid[split] = {}\n",
    "    lbl1c_valid[split] = {}\n",
    "\n",
    "    for prsn in tqdm(splits[split]['train']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl_id,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))\n",
    "            lbl1c_train[split].append(lbl)\n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            ids_shuffle, ids_restore, ids_keep = mae_bank.propose_masking(len(x), mae_bank.num_patches, msk_ratio)\n",
    "\n",
    "            x = x.to(devc)\n",
    "            ids_shuffle = ids_shuffle.to(devc)\n",
    "            ids_restore = ids_restore.to(devc)\n",
    "            ids_keep = ids_keep.to(devc)\n",
    "\n",
    "            latent, mask = mae2c.forward_encoder(x, msk_ratio, ids_shuffle, ids_restore, ids_keep)        \n",
    "\n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_shuffle = ids_shuffle.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            ids_keep = ids_keep.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        if (len(sig1c_train[split]))==0:\n",
    "            sig1c_train[split] = latent[:,0,:].detach().numpy()\n",
    "        else:\n",
    "            sig1c_train[split] = np.vstack([sig1c_train[split],latent[:,0,:].detach().numpy()])\n",
    "\n",
    "\n",
    "    for prsn in tqdm(splits[split]['test']):\n",
    "\n",
    "        sig = loadmat(f'/data/nabil/ecg_repr/physionet.org/files/challenge-2021/1.0.3/training/ptb/g1/{prsn}.mat')['val'] * 1.0\n",
    "        sig = sig[chnl_id,:] \n",
    "\n",
    "        lbl = 1 if prsn in myo_label[1] else 0\n",
    "        sig_epsd = []\n",
    "\n",
    "        for st_smpl in range(0,len(sig)-5000,2500):\n",
    "\n",
    "            sig_epsd.append(mean_norm(downsample2(sig[st_smpl:st_smpl+5000])))        \n",
    "\n",
    "        x = torch.unsqueeze(torch.Tensor(sig_epsd), dim=1)\n",
    "        x = x.repeat(n_tries,1,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ids_shuffle, ids_restore, ids_keep = mae_bank.propose_masking(len(x), mae_bank.num_patches, msk_ratio)\n",
    "\n",
    "            x = x.to(devc)\n",
    "            ids_shuffle = ids_shuffle.to(devc)\n",
    "            ids_restore = ids_restore.to(devc)\n",
    "            ids_keep = ids_keep.to(devc)\n",
    "\n",
    "            latent, mask = mae2c.forward_encoder(x, msk_ratio, ids_shuffle, ids_restore, ids_keep)        \n",
    "            \n",
    "            latent = torch.mean(latent.reshape(n_tries,latent.shape[0]//n_tries,latent.shape[1],latent.shape[2]),dim=0)\n",
    "\n",
    "            x = x.to('cpu')\n",
    "            ids_shuffle = ids_shuffle.to('cpu')\n",
    "            ids_restore = ids_restore.to('cpu')\n",
    "            ids_keep = ids_keep.to('cpu')\n",
    "            latent = latent.to('cpu')\n",
    "            mask = mask.to('cpu')\n",
    "\n",
    "        \n",
    "        \n",
    "        sig1c_valid[split][prsn] = latent[:,0,:].detach().numpy()\n",
    "        lbl1c_valid[split][prsn] = lbl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((sig1c_train,lbl1c_train,sig1c_valid,lbl1c_valid), open('./myo_processed/mae2c.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sig1_train,lbl1_train,sig1_valid,lbl1_valid) = pickle.load(open('./myo_processed/mae1.p','rb'))\n",
    "(sig2_train,lbl2_train,sig2_valid,lbl2_valid) = pickle.load(open('./myo_processed/mae2.p','rb'))\n",
    "(sig3_train,lbl3_train,sig3_valid,lbl3_valid) = pickle.load(open('./myo_processed/mae3.p','rb'))\n",
    "(sig4_train,lbl4_train,sig4_valid,lbl4_valid) = pickle.load(open('./myo_processed/mae4.p','rb'))\n",
    "\n",
    "(sig12_train,lbl12_train,sig12_valid,lbl12_valid) = pickle.load(open('./myo_processed/mae12.p','rb'))\n",
    "\n",
    "(sig1c_train,lbl1c_train,sig1c_valid,lbl1c_valid) = pickle.load(open('./myo_processed/mae1c.p','rb'))\n",
    "(sig2c_train,lbl2c_train,sig2c_valid,lbl2c_valid) = pickle.load(open('./myo_processed/mae2c.p','rb'))\n",
    "(sig3c_train,lbl3c_train,sig3c_valid,lbl3c_valid) = pickle.load(open('./myo_processed/mae3c.p','rb'))\n",
    "(sig4c_train,lbl4c_train,sig4c_valid,lbl4c_valid) = pickle.load(open('./myo_processed/mae4c.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for split in range(5):\n",
    "    sclr1 = StandardScaler()\n",
    "    sclr2 = StandardScaler()\n",
    "    sclr3 = StandardScaler()\n",
    "    sclr4 = StandardScaler()\n",
    "    \n",
    "    sclr12 = StandardScaler()\n",
    "    \n",
    "    sclr1c = StandardScaler()\n",
    "    sclr2c = StandardScaler()\n",
    "    sclr3c = StandardScaler()\n",
    "    sclr4c = StandardScaler()\n",
    "\n",
    "    sig1_train[split] = sclr1.fit_transform(sig1_train[split])\n",
    "    sig2_train[split] = sclr2.fit_transform(sig2_train[split])\n",
    "    sig3_train[split] = sclr3.fit_transform(sig3_train[split])\n",
    "    sig4_train[split] = sclr4.fit_transform(sig4_train[split])\n",
    "\n",
    "    sig1c_train[split] = sclr1c.fit_transform(sig1c_train[split])\n",
    "    sig2c_train[split] = sclr2c.fit_transform(sig2c_train[split])\n",
    "    sig3c_train[split] = sclr3c.fit_transform(sig3c_train[split])\n",
    "    sig4c_train[split] = sclr4c.fit_transform(sig4c_train[split])\n",
    "    \n",
    "    sig12_train[split] = sclr12.fit_transform(sig12_train[split])\n",
    "\n",
    "\n",
    "    for prsn in sig1_valid[split]:\n",
    "        sig1_valid[split][prsn] = sclr1.transform(sig1_valid[split][prsn])\n",
    "        sig2_valid[split][prsn] = sclr2.transform(sig2_valid[split][prsn])\n",
    "        sig3_valid[split][prsn] = sclr3.transform(sig3_valid[split][prsn])\n",
    "        sig4_valid[split][prsn] = sclr4.transform(sig4_valid[split][prsn])\n",
    "\n",
    "        sig1c_valid[split][prsn] = sclr1c.transform(sig1c_valid[split][prsn])\n",
    "        sig2c_valid[split][prsn] = sclr2c.transform(sig2c_valid[split][prsn])\n",
    "        sig3c_valid[split][prsn] = sclr3c.transform(sig3c_valid[split][prsn])\n",
    "        sig4c_valid[split][prsn] = sclr4c.transform(sig4c_valid[split][prsn])\n",
    "\n",
    "        sig12_valid[split][prsn] = sclr12.transform(sig12_valid[split][prsn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:00<00:00, 48.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf12s = {}\n",
    "for fld in tqdm(range(5)):\n",
    "    clf12s[fld] = RandomForestClassifier(random_state=2)\n",
    "    #clf12s[fld] = LogisticRegression(random_state=2)\n",
    "    #clf12s[fld] = DecisionTreeClassifier(random_state=2)\n",
    "    clf12s[fld].fit(sig12_train[fld],lbl12_train[fld])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred12 = {}\n",
    "\n",
    "\n",
    "for fld in range(5):\n",
    "    y_pred12[fld] = {}\n",
    "    for prsn in sig12_valid[fld]:\n",
    "\n",
    "        y_pred12[fld][prsn] = clf12s[fld].predict(sig12_valid[fld][prsn])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:17<00:00, 195.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf1cs = {}\n",
    "clf2cs = {}\n",
    "clf3cs = {}\n",
    "clf4cs = {}\n",
    "\n",
    "for fld in tqdm(range(5)):\n",
    "    clf1cs[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf2cs[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf3cs[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf4cs[fld] = RandomForestClassifier(random_state=2)\n",
    "    \n",
    "    #clf1cs[fld] = LogisticRegression(random_state=2)\n",
    "    #clf2cs[fld] = LogisticRegression(random_state=2)\n",
    "    #clf3cs[fld] = LogisticRegression(random_state=2)\n",
    "    #clf4cs[fld] = LogisticRegression(random_state=2)\n",
    "\n",
    "    #clf1cs[fld] = DecisionTreeClassifier(random_state=2)\n",
    "    \n",
    "    clf1cs[fld].fit(sig1c_train[fld],lbl1c_train[fld])\n",
    "    clf2cs[fld].fit(sig2c_train[fld],lbl2c_train[fld])\n",
    "    clf3cs[fld].fit(sig3c_train[fld],lbl3c_train[fld])\n",
    "    clf4cs[fld].fit(sig4c_train[fld],lbl4c_train[fld])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1c = {}\n",
    "y_pred2c = {}\n",
    "y_pred3c = {}\n",
    "y_pred4c = {}\n",
    "\n",
    "for fld in range(5):\n",
    "    y_pred1c[fld] = {}\n",
    "    y_pred2c[fld] = {}\n",
    "    y_pred3c[fld] = {}\n",
    "    y_pred4c[fld] = {}\n",
    "\n",
    "    for prsn in sig1c_valid[fld]:\n",
    "        y_pred1c[fld][prsn] = clf1cs[fld].predict(sig1c_valid[fld][prsn])\n",
    "        y_pred2c[fld][prsn] = clf2cs[fld].predict(sig2c_valid[fld][prsn])\n",
    "        y_pred3c[fld][prsn] = clf3cs[fld].predict(sig3c_valid[fld][prsn])\n",
    "        y_pred4c[fld][prsn] = clf4cs[fld].predict(sig4c_valid[fld][prsn])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:31<00:00, 198.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf1s = {}\n",
    "clf2s = {}\n",
    "clf3s = {}\n",
    "clf4s = {}\n",
    "\n",
    "for fld in tqdm(range(5)):\n",
    "\n",
    "    clf1s[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf2s[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf3s[fld] = RandomForestClassifier(random_state=2)\n",
    "    clf4s[fld] = RandomForestClassifier(random_state=2)\n",
    "    \n",
    "    #clf1s[fld] = LogisticRegression(random_state=2)\n",
    "    #clf2s[fld] = LogisticRegression(random_state=2)\n",
    "    #clf3s[fld] = LogisticRegression(random_state=2)\n",
    "    #clf4s[fld] = LogisticRegression(random_state=2)\n",
    "\n",
    "    #clf1s[fld] = DecisionTreeClassifier(random_state=2)\n",
    "    \n",
    "    clf1s[fld].fit(sig1_train[fld],lbl1_train[fld])\n",
    "    clf2s[fld].fit(sig2_train[fld],lbl2_train[fld])\n",
    "    clf3s[fld].fit(sig3_train[fld],lbl3_train[fld])\n",
    "    clf4s[fld].fit(sig4_train[fld],lbl4_train[fld])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = {}\n",
    "y_pred2 = {}\n",
    "y_pred3 = {}\n",
    "y_pred4 = {}\n",
    "\n",
    "for fld in range(5):\n",
    "\n",
    "    y_pred1[fld] = {}\n",
    "    y_pred2[fld] = {}\n",
    "    y_pred3[fld] = {}\n",
    "    y_pred4[fld] = {}\n",
    "    \n",
    "    for prsn in sig1_valid[fld] :\n",
    "\n",
    "        y_pred1[fld][prsn] = clf1s[fld].predict(sig1_valid[fld][prsn])\n",
    "        y_pred2[fld][prsn] = clf2s[fld].predict(sig2_valid[fld][prsn])\n",
    "        y_pred3[fld][prsn] = clf3s[fld].predict(sig3_valid[fld][prsn])\n",
    "        y_pred4[fld][prsn] = clf4s[fld].predict(sig4_valid[fld][prsn])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Single Channel\n",
      "Channel 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.63        30\n",
      "           1       0.83      0.93      0.88        74\n",
      "\n",
      "    accuracy                           0.82       104\n",
      "   macro avg       0.80      0.73      0.75       104\n",
      "weighted avg       0.81      0.82      0.81       104\n",
      "\n",
      "Channel 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75        30\n",
      "           1       0.86      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.88       104\n",
      "   macro avg       0.93      0.80      0.84       104\n",
      "weighted avg       0.90      0.88      0.87       104\n",
      "\n",
      "Channel 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.53      0.67        30\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.85       104\n",
      "   macro avg       0.86      0.75      0.78       104\n",
      "weighted avg       0.85      0.85      0.83       104\n",
      "\n",
      "Channel 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69        30\n",
      "           1       0.85      0.97      0.91        74\n",
      "\n",
      "    accuracy                           0.86       104\n",
      "   macro avg       0.87      0.77      0.80       104\n",
      "weighted avg       0.86      0.86      0.84       104\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69        30\n",
      "           1       0.85      0.97      0.91        74\n",
      "\n",
      "    accuracy                           0.86       104\n",
      "   macro avg       0.87      0.77      0.80       104\n",
      "weighted avg       0.86      0.86      0.84       104\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.63      0.76        30\n",
      "           1       0.87      0.99      0.92        74\n",
      "\n",
      "    accuracy                           0.88       104\n",
      "   macro avg       0.91      0.81      0.84       104\n",
      "weighted avg       0.89      0.88      0.88       104\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.53      0.67        30\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.85       104\n",
      "   macro avg       0.86      0.75      0.78       104\n",
      "weighted avg       0.85      0.85      0.83       104\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69        30\n",
      "           1       0.85      0.97      0.91        74\n",
      "\n",
      "    accuracy                           0.86       104\n",
      "   macro avg       0.87      0.77      0.80       104\n",
      "weighted avg       0.86      0.86      0.84       104\n",
      "\n",
      "All Channel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85        30\n",
      "           1       0.91      0.99      0.95        74\n",
      "\n",
      "    accuracy                           0.92       104\n",
      "   macro avg       0.94      0.88      0.90       104\n",
      "weighted avg       0.93      0.92      0.92       104\n",
      "\n",
      "Fold : 1\n",
      "Single Channel\n",
      "Channel 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.53      0.67        30\n",
      "           1       0.84      0.97      0.90        73\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.86      0.75      0.78       103\n",
      "weighted avg       0.85      0.84      0.83       103\n",
      "\n",
      "Channel 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.53      0.65        30\n",
      "           1       0.83      0.96      0.89        73\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.84      0.75      0.77       103\n",
      "weighted avg       0.84      0.83      0.82       103\n",
      "\n",
      "Channel 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.50      0.65        30\n",
      "           1       0.83      0.99      0.90        73\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.88      0.74      0.78       103\n",
      "weighted avg       0.86      0.84      0.83       103\n",
      "\n",
      "Channel 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61        30\n",
      "           1       0.82      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.81      0.72      0.75       103\n",
      "weighted avg       0.81      0.82      0.80       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64        30\n",
      "           1       0.83      0.97      0.89        73\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.85      0.74      0.77       103\n",
      "weighted avg       0.84      0.83      0.82       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61        30\n",
      "           1       0.82      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.81      0.72      0.75       103\n",
      "weighted avg       0.81      0.82      0.80       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        30\n",
      "           1       0.86      0.97      0.91        73\n",
      "\n",
      "    accuracy                           0.86       103\n",
      "   macro avg       0.88      0.79      0.82       103\n",
      "weighted avg       0.87      0.86      0.85       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        30\n",
      "           1       0.86      0.97      0.91        73\n",
      "\n",
      "    accuracy                           0.86       103\n",
      "   macro avg       0.88      0.79      0.82       103\n",
      "weighted avg       0.87      0.86      0.85       103\n",
      "\n",
      "All Channel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77        30\n",
      "           1       0.88      0.97      0.92        73\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.89      0.82      0.85       103\n",
      "weighted avg       0.89      0.88      0.88       103\n",
      "\n",
      "Fold : 2\n",
      "Single Channel\n",
      "Channel 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.40      0.53        30\n",
      "           1       0.80      0.96      0.87        73\n",
      "\n",
      "    accuracy                           0.80       103\n",
      "   macro avg       0.80      0.68      0.70       103\n",
      "weighted avg       0.80      0.80      0.77       103\n",
      "\n",
      "Channel 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.60      0.69        30\n",
      "           1       0.85      0.95      0.90        73\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.84      0.77      0.79       103\n",
      "weighted avg       0.84      0.84      0.84       103\n",
      "\n",
      "Channel 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68        30\n",
      "           1       0.85      0.93      0.89        73\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.82      0.77      0.78       103\n",
      "weighted avg       0.83      0.83      0.83       103\n",
      "\n",
      "Channel 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.50      0.65        30\n",
      "           1       0.83      0.99      0.90        73\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.88      0.74      0.78       103\n",
      "weighted avg       0.86      0.84      0.83       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.47      0.61        30\n",
      "           1       0.82      0.97      0.89        73\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.85      0.72      0.75       103\n",
      "weighted avg       0.83      0.83      0.81       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        30\n",
      "           1       0.89      0.96      0.92        73\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.88      0.83      0.85       103\n",
      "weighted avg       0.88      0.88      0.88       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61        30\n",
      "           1       0.82      0.95      0.88        73\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.81      0.72      0.75       103\n",
      "weighted avg       0.81      0.82      0.80       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71        30\n",
      "           1       0.85      0.99      0.91        73\n",
      "\n",
      "    accuracy                           0.86       103\n",
      "   macro avg       0.90      0.78      0.81       103\n",
      "weighted avg       0.88      0.86      0.85       103\n",
      "\n",
      "All Channel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.78        30\n",
      "           1       0.87      1.00      0.93        73\n",
      "\n",
      "    accuracy                           0.89       103\n",
      "   macro avg       0.93      0.82      0.85       103\n",
      "weighted avg       0.91      0.89      0.88       103\n",
      "\n",
      "Fold : 3\n",
      "Single Channel\n",
      "Channel 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65        29\n",
      "           1       0.86      0.89      0.87        74\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.77      0.76      0.76       103\n",
      "weighted avg       0.81      0.82      0.81       103\n",
      "\n",
      "Channel 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72        29\n",
      "           1       0.87      0.93      0.90        74\n",
      "\n",
      "    accuracy                           0.85       103\n",
      "   macro avg       0.83      0.79      0.81       103\n",
      "weighted avg       0.85      0.85      0.85       103\n",
      "\n",
      "Channel 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.52      0.64        29\n",
      "           1       0.84      0.96      0.89        74\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.83      0.74      0.77       103\n",
      "weighted avg       0.83      0.83      0.82       103\n",
      "\n",
      "Channel 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71        29\n",
      "           1       0.86      0.95      0.90        74\n",
      "\n",
      "    accuracy                           0.85       103\n",
      "   macro avg       0.84      0.78      0.80       103\n",
      "weighted avg       0.85      0.85      0.85       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.69        29\n",
      "           1       0.86      0.96      0.90        74\n",
      "\n",
      "    accuracy                           0.85       103\n",
      "   macro avg       0.85      0.77      0.80       103\n",
      "weighted avg       0.85      0.85      0.85       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.52      0.65        29\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.86      0.75      0.78       103\n",
      "weighted avg       0.85      0.84      0.83       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.45      0.59        29\n",
      "           1       0.82      0.97      0.89        74\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.84      0.71      0.74       103\n",
      "weighted avg       0.83      0.83      0.80       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79        29\n",
      "           1       0.90      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.89       103\n",
      "   macro avg       0.89      0.84      0.86       103\n",
      "weighted avg       0.89      0.89      0.89       103\n",
      "\n",
      "All Channel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82        29\n",
      "           1       0.90      0.99      0.94        74\n",
      "\n",
      "    accuracy                           0.91       103\n",
      "   macro avg       0.93      0.86      0.88       103\n",
      "weighted avg       0.92      0.91      0.91       103\n",
      "\n",
      "Fold : 4\n",
      "Single Channel\n",
      "Channel 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.45      0.54        29\n",
      "           1       0.81      0.92      0.86        74\n",
      "\n",
      "    accuracy                           0.79       103\n",
      "   macro avg       0.75      0.68      0.70       103\n",
      "weighted avg       0.77      0.79      0.77       103\n",
      "\n",
      "Channel 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77        29\n",
      "           1       0.89      0.96      0.92        74\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.88      0.82      0.85       103\n",
      "weighted avg       0.88      0.88      0.88       103\n",
      "\n",
      "Channel 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67        29\n",
      "           1       0.85      0.93      0.89        74\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.81      0.76      0.78       103\n",
      "weighted avg       0.83      0.83      0.83       103\n",
      "\n",
      "Channel 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69        29\n",
      "           1       0.86      0.93      0.90        74\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.82      0.78      0.79       103\n",
      "weighted avg       0.84      0.84      0.84       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.68        29\n",
      "           1       0.85      0.95      0.90        74\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.83      0.77      0.79       103\n",
      "weighted avg       0.84      0.84      0.84       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.81        29\n",
      "           1       0.90      0.97      0.94        74\n",
      "\n",
      "    accuracy                           0.90       103\n",
      "   macro avg       0.91      0.85      0.87       103\n",
      "weighted avg       0.90      0.90      0.90       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76        29\n",
      "           1       0.88      0.97      0.92        74\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.89      0.81      0.84       103\n",
      "weighted avg       0.89      0.88      0.88       103\n",
      "\n",
      "Correlated\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.62      0.72        29\n",
      "           1       0.87      0.96      0.91        74\n",
      "\n",
      "    accuracy                           0.86       103\n",
      "   macro avg       0.86      0.79      0.82       103\n",
      "weighted avg       0.86      0.86      0.86       103\n",
      "\n",
      "All Channel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.62      0.75        29\n",
      "           1       0.87      0.99      0.92        74\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.91      0.80      0.84       103\n",
      "weighted avg       0.89      0.88      0.88       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "for fld in range(5):\n",
    "\n",
    "    print(f'Fold : {fld}')\n",
    "    YT_1 = []\n",
    "    YT_2 = []\n",
    "    YT_3 = []\n",
    "    YT_4 = []    \n",
    "    YT_1C = []    \n",
    "    YT_2C = []    \n",
    "    YT_3C = []    \n",
    "    YT_4C = []    \n",
    "    YT_12 = []\n",
    "\n",
    "    YP_1 = []\n",
    "    YP_2 = []\n",
    "    YP_3 = []\n",
    "    YP_4 = []\n",
    "    YP_1C = []\n",
    "    YP_2C = []\n",
    "    YP_3C = []\n",
    "    YP_4C = []\n",
    "    YP_12 = []\n",
    "\n",
    "    for prsn in sig1_valid[fld]:\n",
    "        YT_1.append(lbl1_valid[fld][prsn])\n",
    "        YT_2.append(lbl2_valid[fld][prsn])\n",
    "        YT_3.append(lbl3_valid[fld][prsn])\n",
    "        YT_4.append(lbl4_valid[fld][prsn])\n",
    "        YT_1C.append(lbl1c_valid[fld][prsn])\n",
    "        YT_2C.append(lbl2c_valid[fld][prsn])\n",
    "        YT_3C.append(lbl3c_valid[fld][prsn])\n",
    "        YT_4C.append(lbl4c_valid[fld][prsn])\n",
    "        YT_12.append(lbl12_valid[fld][prsn])\n",
    "\n",
    "        YP_1.append(round(np.mean(y_pred1[fld][prsn])))\n",
    "        YP_2.append(round(np.mean(y_pred2[fld][prsn])))\n",
    "        YP_3.append(round(np.mean(y_pred3[fld][prsn])))\n",
    "        YP_4.append(round(np.mean(y_pred4[fld][prsn])))\n",
    "        YP_1C.append(round(np.mean(y_pred1c[fld][prsn])))\n",
    "        YP_2C.append(round(np.mean(y_pred2c[fld][prsn])))\n",
    "        YP_3C.append(round(np.mean(y_pred3c[fld][prsn])))\n",
    "        YP_4C.append(round(np.mean(y_pred4c[fld][prsn])))\n",
    "        YP_12.append(round(np.mean(y_pred12[fld][prsn])))\n",
    "        \n",
    "    print('Single Channel')\n",
    "    print('Channel 1')\n",
    "    print(classification_report(YT_1, YP_1))\n",
    "    print('Channel 2')\n",
    "    print(classification_report(YT_2, YP_2))\n",
    "    print('Channel 3')\n",
    "    print(classification_report(YT_3, YP_3))\n",
    "    print('Channel 4')\n",
    "    print(classification_report(YT_4, YP_4))\n",
    "\n",
    "    print('Correlated')\n",
    "    print(classification_report(YT_1C, YP_1C))\n",
    "    print('Correlated')\n",
    "    print(classification_report(YT_2C, YP_2C))\n",
    "    print('Correlated')\n",
    "    print(classification_report(YT_3C, YP_3C))\n",
    "    print('Correlated')\n",
    "    print(classification_report(YT_4C, YP_4C))\n",
    "\n",
    "    print('All Channel')\n",
    "    print(classification_report(YT_12, YP_12))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "df = []\n",
    "\n",
    "for fld in range(5):\n",
    "    YT_1 = []\n",
    "    YT_2 = []\n",
    "    YT_3 = []\n",
    "    YT_4 = []    \n",
    "    YT_1C = []    \n",
    "    YT_2C = []    \n",
    "    YT_3C = []    \n",
    "    YT_4C = []    \n",
    "    YT_12 = []\n",
    "\n",
    "    YP_1 = []\n",
    "    YP_2 = []\n",
    "    YP_3 = []\n",
    "    YP_4 = []\n",
    "    YP_1C = []\n",
    "    YP_2C = []\n",
    "    YP_3C = []\n",
    "    YP_4C = []\n",
    "    YP_12 = []\n",
    "\n",
    "    for prsn in sig1_valid[fld]:\n",
    "        YT_1.append(lbl1_valid[fld][prsn])\n",
    "        YT_2.append(lbl2_valid[fld][prsn])\n",
    "        YT_3.append(lbl3_valid[fld][prsn])\n",
    "        YT_4.append(lbl4_valid[fld][prsn])\n",
    "        YT_1C.append(lbl1c_valid[fld][prsn])\n",
    "        YT_2C.append(lbl2c_valid[fld][prsn])\n",
    "        YT_3C.append(lbl3c_valid[fld][prsn])\n",
    "        YT_4C.append(lbl4c_valid[fld][prsn])\n",
    "        YT_12.append(lbl12_valid[fld][prsn])\n",
    "\n",
    "        YP_1.append(round(np.mean(y_pred1[fld][prsn])))\n",
    "        YP_2.append(round(np.mean(y_pred2[fld][prsn])))\n",
    "        YP_3.append(round(np.mean(y_pred3[fld][prsn])))\n",
    "        YP_4.append(round(np.mean(y_pred4[fld][prsn])))\n",
    "        YP_1C.append(round(np.mean(y_pred1c[fld][prsn])))\n",
    "        YP_2C.append(round(np.mean(y_pred2c[fld][prsn])))\n",
    "        YP_3C.append(round(np.mean(y_pred3c[fld][prsn])))\n",
    "        YP_4C.append(round(np.mean(y_pred4c[fld][prsn])))\n",
    "        YP_12.append(round(np.mean(y_pred12[fld][prsn])))\n",
    "    \n",
    "    df.append(['Single Channel 1',fld+1,accuracy_score(YT_1, YP_1),precision_score(YT_1, YP_1,average='macro'),recall_score(YT_1, YP_1,average='macro'),f1_score(YT_1, YP_1,average='macro'),roc_auc_score(YT_1, YP_1,average='macro')])\n",
    "    df.append(['Single Channel 2',fld+1,accuracy_score(YT_2, YP_2),precision_score(YT_2, YP_2,average='macro'),recall_score(YT_2, YP_2,average='macro'),f1_score(YT_2, YP_2,average='macro'),roc_auc_score(YT_2, YP_2,average='macro')])\n",
    "    df.append(['Single Channel 3',fld+1,accuracy_score(YT_3, YP_3),precision_score(YT_3, YP_3,average='macro'),recall_score(YT_3, YP_3,average='macro'),f1_score(YT_3, YP_3,average='macro'),roc_auc_score(YT_3, YP_3,average='macro')])\n",
    "    df.append(['Single Channel 4',fld+1,accuracy_score(YT_4, YP_1),precision_score(YT_4, YP_4,average='macro'),recall_score(YT_4, YP_4,average='macro'),f1_score(YT_4, YP_4,average='macro'),roc_auc_score(YT_4, YP_4,average='macro')])\n",
    "\n",
    "    df.append(['Correlated Channel 1',fld+1,accuracy_score(YT_1C, YP_1C),precision_score(YT_1C, YP_1C,average='macro'),recall_score(YT_1C, YP_1C,average='macro'),f1_score(YT_1C, YP_1C,average='macro'),roc_auc_score(YT_1C, YP_1C,average='macro')])\n",
    "    df.append(['Correlated Channel 2',fld+1,accuracy_score(YT_2C, YP_2C),precision_score(YT_2C, YP_2C,average='macro'),recall_score(YT_2C, YP_2C,average='macro'),f1_score(YT_2C, YP_2C,average='macro'),roc_auc_score(YT_2C, YP_2C,average='macro')])\n",
    "    df.append(['Correlated Channel 3',fld+1,accuracy_score(YT_3C, YP_3C),precision_score(YT_3C, YP_3C,average='macro'),recall_score(YT_3C, YP_3C,average='macro'),f1_score(YT_3C, YP_3C,average='macro'),roc_auc_score(YT_3C, YP_3C,average='macro')])\n",
    "    df.append(['Correlated Channel 4',fld+1,accuracy_score(YT_4C, YP_4C),precision_score(YT_4C, YP_4C,average='macro'),recall_score(YT_4C, YP_4C,average='macro'),f1_score(YT_4C, YP_4C,average='macro'),roc_auc_score(YT_4C, YP_4C,average='macro')])\n",
    "    \n",
    "    df.append(['All 12 Channels',fld+1,accuracy_score(YT_12, YP_12),precision_score(YT_12, YP_12,average='macro'),recall_score(YT_12, YP_12,average='macro'),f1_score(YT_12, YP_12,average='macro'),roc_auc_score(YT_12, YP_12,average='macro')])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df, columns=['Model','Fold','Accuracy','Precision','Recall','F1 Score', 'AUC'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp = open('./myo_processed/LR.csv','w')\n",
    "#fp.write(df.to_csv())\n",
    "#fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Model', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All 12 Channels</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.901214</td>\n",
       "      <td>0.884230</td>\n",
       "      <td>0.873847</td>\n",
       "      <td>0.877521</td>\n",
       "      <td>0.873847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837248</td>\n",
       "      <td>0.813563</td>\n",
       "      <td>0.776690</td>\n",
       "      <td>0.789627</td>\n",
       "      <td>0.776690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.870108</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.830561</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.830561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.819698</td>\n",
       "      <td>0.789279</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.767580</td>\n",
       "      <td>0.754310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.854668</td>\n",
       "      <td>0.832552</td>\n",
       "      <td>0.801586</td>\n",
       "      <td>0.813884</td>\n",
       "      <td>0.801586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.821695</td>\n",
       "      <td>0.804769</td>\n",
       "      <td>0.735630</td>\n",
       "      <td>0.756880</td>\n",
       "      <td>0.735630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.860437</td>\n",
       "      <td>0.842762</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.821428</td>\n",
       "      <td>0.807355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.827446</td>\n",
       "      <td>0.801840</td>\n",
       "      <td>0.761794</td>\n",
       "      <td>0.776763</td>\n",
       "      <td>0.761794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.821695</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.764496</td>\n",
       "      <td>0.781249</td>\n",
       "      <td>0.764496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Fold  Accuracy  Precision    Recall  F1 Score       AUC\n",
       "Model                                                                        \n",
       "All 12 Channels        3.0  0.901214   0.884230  0.873847  0.877521  0.873847\n",
       "Correlated Channel 1   3.0  0.837248   0.813563  0.776690  0.789627  0.776690\n",
       "Correlated Channel 2   3.0  0.870108   0.847646  0.830561  0.837622  0.830561\n",
       "Correlated Channel 3   3.0  0.819698   0.789279  0.754310  0.767580  0.754310\n",
       "Correlated Channel 4   3.0  0.854668   0.832552  0.801586  0.813884  0.801586\n",
       "Single Channel 1       3.0  0.821695   0.804769  0.735630  0.756880  0.735630\n",
       "Single Channel 2       3.0  0.860437   0.842762  0.807355  0.821428  0.807355\n",
       "Single Channel 3       3.0  0.827446   0.801840  0.761794  0.776763  0.761794\n",
       "Single Channel 4       3.0  0.821695   0.810760  0.764496  0.781249  0.764496"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All 12 Channels</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.032091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 1</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>0.032458</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.032458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 2</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>0.038611</td>\n",
       "      <td>0.038865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 3</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.033139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated Channel 4</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.032492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 1</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.026304</td>\n",
       "      <td>0.041313</td>\n",
       "      <td>0.034029</td>\n",
       "      <td>0.036781</td>\n",
       "      <td>0.034029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 2</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>0.033323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 3</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.034270</td>\n",
       "      <td>0.057157</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.031462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single Channel 4</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.026304</td>\n",
       "      <td>0.051718</td>\n",
       "      <td>0.047383</td>\n",
       "      <td>0.049107</td>\n",
       "      <td>0.047383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Fold  Accuracy  Precision    Recall  F1 Score   \n",
       "Model                                                                     \n",
       "All 12 Channels       1.581139  0.021770   0.027420  0.032091  0.028205  \\\n",
       "Correlated Channel 1  1.581139  0.021722   0.029810  0.032458  0.028735   \n",
       "Correlated Channel 2  1.581139  0.031354   0.041945  0.038865  0.038611   \n",
       "Correlated Channel 3  1.581139  0.033015   0.052946  0.033139  0.039467   \n",
       "Correlated Channel 4  1.581139  0.021552   0.024858  0.032492  0.029015   \n",
       "Single Channel 1      1.581139  0.026304   0.041313  0.034029  0.036781   \n",
       "Single Channel 2      1.581139  0.031296   0.043347  0.033323  0.035959   \n",
       "Single Channel 3      1.581139  0.034270   0.057157  0.031462  0.039702   \n",
       "Single Channel 4      1.581139  0.026304   0.051718  0.047383  0.049107   \n",
       "\n",
       "                           AUC  \n",
       "Model                           \n",
       "All 12 Channels       0.032091  \n",
       "Correlated Channel 1  0.032458  \n",
       "Correlated Channel 2  0.038865  \n",
       "Correlated Channel 3  0.033139  \n",
       "Correlated Channel 4  0.032492  \n",
       "Single Channel 1      0.034029  \n",
       "Single Channel 2      0.033323  \n",
       "Single Channel 3      0.031462  \n",
       "Single Channel 4      0.047383  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Model').std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_repr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
